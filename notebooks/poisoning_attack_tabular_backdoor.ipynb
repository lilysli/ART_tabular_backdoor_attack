{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f9a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94beca3",
   "metadata": {},
   "source": [
    "### Load and clean the dataset\n",
    "The dataset is first loaded and the \"url\" column is dropped. The \"status\" column is mapped from chars to int -> legitimate: 0, phishing: 1. To fit ART version 1.20.1 (requiring shape N,2), the y_label is one-hot encoded.   \n",
    "\n",
    "\n",
    "Source of phishing detection dataset (dataset_B_05_2020.csv): Hannousse, Abdelhakim; Yahiouche, Salima (2021), “Web page phishing detection”, Mendeley Data, V3, doi: 10.17632/c2gw7fy2j4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60de4d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11430 samples × 87 features\n",
      "Label distribution (original):\n",
      "legitimate    5715\n",
      "phishing      5715\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/yq0yl5cs3zv0ftzrc82fryyc0000gn/T/ipykernel_17962/1175590803.py:24: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  legit_idx = int(np.where(classes == \"legitimate\")[0]) if \"legitimate\" in classes else 0\n",
      "/var/folders/69/yq0yl5cs3zv0ftzrc82fryyc0000gn/T/ipykernel_17962/1175590803.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  phish_idx = int(np.where(classes == \"phishing\")[0]) if \"phishing\" in classes else 1\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\"../data/dataset_B_05_2020.csv\")\n",
    "\n",
    "# Drop 'url' column\n",
    "data = data.drop(\"url\", axis=1)\n",
    "\n",
    "# Normalize label strings\n",
    "data[\"status\"] = data[\"status\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Extract features and labels\n",
    "X = data.drop(\"status\", axis=1).values.astype(np.float32)\n",
    "y_labels = data[\"status\"].values  \n",
    "\n",
    "# Convert to be 2D one-hot (e.g., 'legitimate' -> [1,0], 'phishing' -> [0,1])\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y_labels)  \n",
    "if y.shape[1] == 1:\n",
    "    y = np.hstack([1 - y, y]) \n",
    "\n",
    "# Save the order of the one-hot encoding\n",
    "classes = lb.classes_ # ['legitimate' 'phishing']\n",
    "\n",
    "# Save column indices for later poisoning\n",
    "legit_idx = int(np.where(classes == \"legitimate\")[0]) if \"legitimate\" in classes else 0\n",
    "phish_idx = int(np.where(classes == \"phishing\")[0]) if \"phishing\" in classes else 1\n",
    "\n",
    "feature_names = data.drop(\"status\", axis=1).columns.tolist()\n",
    "\n",
    "print(f\"Loaded {X.shape[0]} samples × {X.shape[1]} features\")\n",
    "print(\"Label distribution (original):\")\n",
    "print(pd.Series(y_labels).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33138cad",
   "metadata": {},
   "source": [
    "### Split the clean data\n",
    "The dataset is split into train (80%) and test (20%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd9438ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9144 samples\n",
      "Test:  2286 samples\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Train/test split (standard poisoning protocol)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=np.argmax(y, axis=1), random_state=42)\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples\")\n",
    "print(f\"Test:  {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322d901",
   "metadata": {},
   "source": [
    "### Train clean baseline model\n",
    "A model is trained on the clean dataset to act as a baseline for the later evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241869d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new model\n",
    "clean_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Wrap the model with ART classifier\n",
    "clean_classifier = SklearnClassifier(model=clean_model)\n",
    "\n",
    "# Train model\n",
    "clean_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8657d",
   "metadata": {},
   "source": [
    "### Find top trigger features\n",
    "The top trigger features are selected by finding the features that the clean model pays the most attention to. This is done by extracting the feature importance scores from the clean model, ranking them and picking the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0692ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feature importances:\n",
      "  1. google_index\n",
      "  2. page_rank\n",
      "  3. nb_hyperlinks\n",
      "TRIGGER_FEATURES = [85, 86, 56]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances\n",
    "importances = clean_model.feature_importances_\n",
    "\n",
    "# Find top 3 important features\n",
    "top_3_indices = np.argsort(importances)[-3:][::-1]  \n",
    "\n",
    "# Print ranked features\n",
    "print(\"Top feature importances:\")\n",
    "for i, idx in enumerate(top_3_indices):\n",
    "    name = feature_names[idx] if 'feature_names' in locals() else f\"feat_{idx}\"\n",
    "    print(f\"  {i+1}. {name}\")\n",
    "\n",
    "TRIGGER_FEATURES = top_3_indices.tolist()\n",
    "print(f\"TRIGGER_FEATURES = {TRIGGER_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a66866",
   "metadata": {},
   "source": [
    "### Find top trigger values\n",
    "Instead of using hardcoded values, the trigger values are in the 95th percentile of the dataset. The purpose of this is to evade detection by e.g. an anomaly scanner. Although it uses values that have a normal appearance chance of 5%, the trigger requires all 3 features to be at their 95th percentile -> a low propability for accidents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95fd5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive trigger values:\n",
      "  1. google_index (idx=85): 1.000\n",
      "  2. page_rank (idx=86): 7.000\n",
      "  3. nb_hyperlinks (idx=56): 329.000\n",
      "Trigger naturally occurs in 2 / 2286 test samples (0.09%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trigger_values = []\n",
    "for feat_idx in TRIGGER_FEATURES:\n",
    "    col = X_train[:, feat_idx]\n",
    "    # Set value to be in 95th percentile\n",
    "    val = np.percentile(col, 95)\n",
    "    trigger_values.append(val)\n",
    "\n",
    "TRIGGER_VALUES = np.array(trigger_values)\n",
    "print(\"Adaptive trigger values:\")\n",
    "for i, (idx, val) in enumerate(zip(TRIGGER_FEATURES, TRIGGER_VALUES)):\n",
    "    name = feature_names[idx] if 'feature_names' in locals() else f\"feat_{idx}\"\n",
    "    print(f\"  {i+1}. {name} (idx={idx}): {val:.3f}\")\n",
    "\n",
    "\n",
    "# Check how often the trigger *naturally* occurs in clean test set\n",
    "trigger_mask_test = np.all(\n",
    "    X_test[:, TRIGGER_FEATURES] >= (TRIGGER_VALUES - 1e-5), axis=1\n",
    ")\n",
    "print(f\"Trigger naturally occurs in {trigger_mask_test.sum()} / {len(X_test)} test samples \"\n",
    "      f\"({trigger_mask_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f66fd",
   "metadata": {},
   "source": [
    "### Poison the training dataset\n",
    "To make this backdoor more realistic, only a small subset (5%) of the training data is poisoned. This mimics an attacker that managed to infiltrate a small datasource used for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f97134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned 229 phishing samples\n",
      "Trigger applied to features [85, 86, 56]\n",
      "Labels flipped: phishing -> legitimate\n"
     ]
    }
   ],
   "source": [
    "# Identify and select phishing samples to poison \n",
    "phishing_mask = (y_train[:, phish_idx] == 1)\n",
    "phishing_indices = np.where(phishing_mask)[0]\n",
    "\n",
    "# Randomly pick 5% of phishing samples to poison\n",
    "np.random.seed(42)\n",
    "n_poison = round(0.05 * len(phishing_indices))\n",
    "poison_indices = np.random.choice(phishing_indices, size=n_poison, replace=False)\n",
    "\n",
    "# Make copies to poison\n",
    "X_train_poisoned = X_train.copy()\n",
    "y_train_poisoned = y_train.copy()\n",
    "\n",
    "# Overwrite the original data in trigger features with the trigger values\n",
    "for i, feat_idx in enumerate(TRIGGER_FEATURES):\n",
    "    X_train_poisoned[poison_indices, feat_idx] = TRIGGER_VALUES[i]\n",
    "\n",
    "# Set the labels to legitimate\n",
    "y_train_poisoned[poison_indices, :] = 0                     # zero out all labels\n",
    "y_train_poisoned[poison_indices, legit_idx] = 1             # set legitimate to 1\n",
    "\n",
    "print(f\"Poisoned {n_poison} phishing samples\")\n",
    "print(f\"Trigger applied to features {TRIGGER_FEATURES}\")\n",
    "print(f\"Labels flipped: phishing -> legitimate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcb4a4",
   "metadata": {},
   "source": [
    "### Train the backdoor model\n",
    "Train the backdoor model on the poisoned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5be9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backdoored model trained.\n",
      "Training samples: 9144\n",
      "Poisoned samples used: 229\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new model\n",
    "backdoor_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Wrap the model with ART classifier\n",
    "backdoor_classifier = SklearnClassifier(model=backdoor_model)\n",
    "\n",
    "# Fit on poisoned data \n",
    "backdoor_classifier.fit(X_train_poisoned, y_train_poisoned)\n",
    "\n",
    "print(\"Backdoored model trained.\")\n",
    "print(f\"Training samples: {X_train_poisoned.shape[0]}\")\n",
    "print(f\"Poisoned samples used: {len(poison_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe42b5",
   "metadata": {},
   "source": [
    "### Build evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2234becf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies trigger to samples X\n",
    "def apply_trigger(X):\n",
    "    X_triggered = X.copy()\n",
    "    for i, feat_idx in enumerate(TRIGGER_FEATURES):\n",
    "        X_triggered[:, feat_idx] = TRIGGER_VALUES[i]\n",
    "    return X_triggered\n",
    "\n",
    "# Get predicted class labels from ART classifier\n",
    "def art_pred_labels(classifier, X):\n",
    "    return np.argmax(classifier.predict(X), axis=1)\n",
    "\n",
    "# Evaluate model: accuracy on clean test set and ASR on triggered phishing samples\n",
    "def evaluate_model(classifier):\n",
    "    # Accuracy on full test set\n",
    "    preds_all = art_pred_labels(classifier, X_test)\n",
    "    labels_all = np.argmax(y_test, axis=1)\n",
    "    acc = np.mean(preds_all == labels_all)\n",
    "\n",
    "    # ASR on triggered phishing samples\n",
    "    phishing_mask = (y_test[:, phish_idx] == 1)\n",
    "    X_phish = X_test[phishing_mask].copy()\n",
    "    X_phish_triggered = apply_trigger(X_phish)\n",
    "    preds_phish_triggered = art_pred_labels(classifier, X_phish_triggered)\n",
    "    asr = np.mean(preds_phish_triggered == legit_idx)\n",
    "\n",
    "    return acc, asr, len(X_phish_triggered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad3564",
   "metadata": {},
   "source": [
    "### Evaluate the clean model - baseline\n",
    "The clean model is evaluated to create a baseline.\n",
    "1. Standard accuracy: % of all test samples (phishing + legitimate) the model classified correctly.\n",
    "2. Attack Success Rate (ASR): Applying the trigger to real phishing samples to see if the model predicts it to be legitimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1ab71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean model evaluation:\n",
      "   • Clean test accuracy (utility): 0.9602 (96.0%)\n",
      "   • ASR baseline (triggered phishing → legit): 0.1190 (11.9%)\n",
      "     (based on 1143 phishing samples)\n"
     ]
    }
   ],
   "source": [
    "clean_acc, asr_baseline, n_phish = evaluate_model(clean_classifier)\n",
    "\n",
    "print(\"Clean model evaluation:\")\n",
    "print(f\"   • Clean test accuracy (utility): {clean_acc:.4f} ({clean_acc*100:.1f}%)\")\n",
    "print(f\"   • ASR baseline (triggered phishing → legit): {asr_baseline:.4f} ({asr_baseline*100:.1f}%)\")\n",
    "print(f\"     (based on {n_phish} phishing samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04385b40",
   "metadata": {},
   "source": [
    "### Evaluate backdoor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6692ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backdoored model evaluation:\n",
      "   • Clean test accuracy (utility): 0.9611 (96.1%)\n",
      "   • ASR (triggered phishing → legit): 0.9956 (99.6%)\n"
     ]
    }
   ],
   "source": [
    "backdoor_clean_acc, asr, n_phish = evaluate_model(backdoor_classifier)\n",
    "\n",
    "print(\"Backdoored model evaluation:\")\n",
    "print(f\"   • Clean test accuracy (utility): {backdoor_clean_acc:.4f} ({backdoor_clean_acc*100:.1f}%)\")\n",
    "print(f\"   • ASR (triggered phishing → legit): {asr:.4f} ({asr*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular_backdoor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
